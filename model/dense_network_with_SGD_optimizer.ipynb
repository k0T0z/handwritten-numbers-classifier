{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn as nn\n",
    "from torch.optim import SGD as sgd # Stochastic Gradient Descent\n",
    "import pandas as pd\n",
    "import torchviz\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        self.dataset = pd.read_csv(filepath)\n",
    "\n",
    "        self.x = self.dataset.iloc[:, 1:].values  # all columns except the first one\n",
    "        self.y = self.dataset.iloc[:, 0].values  # first column is the label\n",
    "\n",
    "        # Reshape features into images (assuming images are 28x28 pixels)\n",
    "        self.x = self.x.reshape(-1, 28, 28)\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        self.x = torch.tensor(self.x)\n",
    "        self.y = torch.tensor(self.y)\n",
    "\n",
    "        # TODO: Is this the right place for normalization? As this may affect the convolutional layers!\n",
    "        # Normalize image pixels\n",
    "        self.x = self.x / 255.0\n",
    "\n",
    "        # Encoding labels into one-hot vectors\n",
    "        self.y = F.one_hot(self.y, num_classes=10).to(float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CDataset(\"mnist_train.csv\")\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CDataset(\"mnist_test.csv\")\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_ds, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ANN with 2 hidden layers using ReLU activation function with bias.\n",
    "#\n",
    "\n",
    "class NN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Matrix1 = nn.Linear(28**2, 100)\n",
    "        self.Matrix2 = nn.Linear(100, 50)\n",
    "        self.Matrix3 = nn.Linear(50, 10)\n",
    "        \n",
    "        self.R = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Converting images from matrices to vectors (AKA flattening)\n",
    "        x = x.view(-1, 28**2)\n",
    "\n",
    "        x = self.R(self.Matrix1(x))\n",
    "        x = self.R(self.Matrix2(x))\n",
    "\n",
    "        # TODO: Is this the right place for softmax?\n",
    "        x = self.Matrix3(x)\n",
    "        \n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model function\n",
    "def train_model(dl, nni, n_epochs=20, lr=0.01):\n",
    "    # Optimization\n",
    "    opt = sgd(nni.parameters(), lr=lr)\n",
    "    L = nn.MSELoss()\n",
    "\n",
    "    # Train model\n",
    "    losses = []\n",
    "    epochs = []\n",
    "    time_stamps = []\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    # Loop over the dataset multiple times\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        N = len(dl) # 12'000 batches\n",
    "        \n",
    "        # Loop over all batches\n",
    "        for i, (x, y) in enumerate(dl):\n",
    "            # Update the weights of the network\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # TODO: Why do we need to convert to float?\n",
    "            x = x.to(torch.float32)  # Convert input data to Float\n",
    "            y = y.to(torch.float32)  # Convert labels to Float\n",
    "\n",
    "            loss_value = L(nni(x), y)\n",
    "            loss_value.backward()\n",
    "            opt.step()\n",
    "            # Store training data for plotting\n",
    "            epochs.append(epoch + i / N) # epochs.append(epoch + i / N)\n",
    "            losses.append(loss_value.item())\n",
    "            time_stamps.append(time() - start)\n",
    "\n",
    "    return np.array(epochs), np.array(losses), np.array(time_stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_epochs_data = []\n",
    "global_loss_data = []\n",
    "global_time_stamps = []\n",
    "\n",
    "nn1 = NN1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not nn1.training:\n",
    "    nn1.train()\n",
    "\n",
    "epoch_data, loss_data, time_stamps = train_model(train_dl, nn1, n_epochs=50)\n",
    "\n",
    "global_epochs_data.extend(epoch_data.tolist())\n",
    "global_loss_data.extend(loss_data.tolist())\n",
    "global_time_stamps.extend(time_stamps.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_data, loss_data)\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE (per batch)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_data = epoch_data.reshape(20,-1).mean(axis=1)\n",
    "loss_data = loss_data.reshape(20,-1).mean(axis=1)\n",
    "time_stamps = time_stamps.reshape(20,-1).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_stamps, loss_data, marker='o', label='Loss')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE (per batch)\")\n",
    "plt.legend()\n",
    "# plt.savefig(\"plt.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "if nn1.training:\n",
    "    nn1.eval()\n",
    "\n",
    "# Iterate over the test data\n",
    "with torch.no_grad():\n",
    "    for x, y in test_dl:\n",
    "        # Make predictions\n",
    "        outputs = nn1(x)\n",
    "\n",
    "        # Get predicted class labels\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # Convert one-hot encoded labels to class indices\n",
    "        y = torch.argmax(y, dim=1)\n",
    "        \n",
    "        # Compare predicted labels with actual labels\n",
    "        correct_predictions += (predicted_labels == y).sum().item()\n",
    "        total_samples += y.size(0)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f\"Loss: {loss_data[len(loss_data)-1]:.9f}\")\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Correct predictions: {correct_predictions}\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
